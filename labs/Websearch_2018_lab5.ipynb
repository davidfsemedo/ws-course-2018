{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Search 2018 - Tutorial 5: Multi-Feature Label Propagation\n",
    "## Contents\n",
    "\n",
    "1. [Overview](#head1)\n",
    "  1. [Code Imports](#head11)\n",
    "2. [Iterative Label Propagation on Web Data](#head2)\n",
    "  1. [Multi-label LP Algorithm](#head21)\n",
    "  2. [Implement the Multi-label LP Algorithm](#head22)\n",
    "  3. [Evaluation](#head23)\n",
    "  4. [Exercises](#head24)\n",
    "3. [Multi-Feature Iterative Label Propagation](#head3)\n",
    "  1. [Implement the Multi-Feature Iterative Label Propagation](#head31)\n",
    "  2. [Exercises](#head32)\n",
    "\n",
    "## <a name=\"head1\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab you implemented the Iterative Label Propagation algorithm, which consists of a semi-supervised graph approach to annotate uncategorized/unlabelled data starting from a small set of categorized/labelled data.\n",
    "\n",
    "The target dataset was the MNIST Digits, which is only adequate for implementation purposes (i.e. testing, debugging, etc.). In this lab, the first step will be to apply the LP algorithm to Web data and analyse its behaviour.\n",
    "\n",
    "\n",
    "Additionally, in the LP implementation of the previous lab, semantic affinity between documents (images/texts) was computed based on a **single feature space**. In this lab the LP algorithm definition will be revisited in order to accomodate the computation of semantic affinity between documents under **multiple feature spaces**. This will allow the construction of a much more richer graph, supporting propagation of labels by different similarity criteria. \n",
    "\n",
    "\n",
    "**Lab objectives:**\n",
    "* Apply the iterative version of the Label Propagation algorithm to Web data scenario and analyse the results;\n",
    "* Implement the Multi-feature iterative Label Propagation algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"head11\"></a> Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head2\"></a> Iterative Label Propagation on Web Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a dataset $X=\\{x_1, x_2, \\ldots, x_L, \\ \\ x_{L+1}, \\ldots, x_N\\}$, with $N$ data points, where each $x_i$ consists of some feature representation of document $i$. Given a categories set $C=\\{1, 2, \\ldots, |C|\\}$, it is assumed that the first $L$ data points are labelled with a label $c \\in C$, and the remaining ones are unlabelled.\n",
    "\n",
    "Please refer to the \"Mining Data Graphs\" class (lectured on 29/10), namely slides 28, 29 and 30, for a description of the algorithm steps.\n",
    "\n",
    "For more information, you can check the original paper: Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, Bernhard Schoelkopf. Learning with local and global consistency (2004) http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.115.3219\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"head21\"></a> Multi-label LP Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Iterative LP algorithm on your project dataset and discuss its effectiveness.\n",
    "\n",
    "The dataset has a total of 13 categories. The categories of each document are available in the corresponding line of that document (column 'gt_class'), in the provided .csv file. Multiple categories are separated by a comma ','. You should represent each document's categories as a 13-dimensional vector (one-hot encoding), as you did for the MNIST dataset. In this case, you may have more than 1 active dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"head22\"></a> Implement the Multi-label LP Algorithm\n",
    "\n",
    "**Multi-label LP:** As each document has multiple categories, you will need to modify your LP implementation. Instead of an **argmax** to select the final category of each document, you will need to **select the top-k categories**, by applying a threshold on the number of categories assigned.\n",
    "\n",
    "**Discuss:** Discuss examples of thresholds (e.g. select the top-3 labels, keep all categories with their values $>\\alpha$, etc.)  .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"head23\"></a>  Evaluation\n",
    "Evaluate the results of each run of the Iterative LP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function classification_report computes and prints a set of commonly used metrics.\n",
    "# docs: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the predictions of the unlabeled documents\n",
    "Y_pred = Y[indices_unlabeled, :]\n",
    "\n",
    "# Get the corresponding groundtruth\n",
    "y_gt = Y_true[indices_unlabeled, :]\n",
    "\n",
    "print(classification_report(y_gt, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"head24\"></a>  Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which feature spaces are more effective? Do a per-class inspection and understand which feature spaces are more effective for each class and why. \n",
    "\n",
    "# How does the LP algorithm behaves when you change the number of initial labels? (variable labeled_set_size on lab4)\n",
    "\n",
    "# Note that documents (Tweets) from your project's dataset have multiple labels, i.e. each document may belong to 1 or more classes. \n",
    "# Discuss how this impacts the label propagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"head3\"></a> Multi-Feature Iterative Label Propagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the computation of the affinity matrix S.\n",
    "\n",
    "Given some feature space representation, each entry $w_{ij}$, for $i\\neq j$ is computed as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "w_{ij} = exp\\Big({-\\frac{||x_i - x_j||^2}{2\\sigma^2}}\\Big),\n",
    "\\end{align}\n",
    "$$\n",
    "where a Gaussian kernel is applied over the distance on the considered feature space.\n",
    "\n",
    "\n",
    "In order compute affinity by considering **multiple feature spaces**, the above expression can be extended as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "w_{ij} = exp\\Big({-\\frac{\\Big[\\sum_{f}\\alpha_f\\cdot||x_i^f - x_j^f||\\Big]^2}{2\\sigma^2}}\\Big),\n",
    "\\end{align}\n",
    "$$\n",
    "where each $x^f$ denotes a given feature space and $\\alpha_f$ the weight associated with that space. The weights should be defined such that $\\sum_f \\alpha_f = 1$.\n",
    "\n",
    "You can define the contribution of each feature space by adequately setting its associated weight $\\alpha_f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=\"head31\"></a> Implement the Multi-Feature Iterative Label Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that given the Multi-label implementation of Iterative LP, you should only need to change the computation of each $w_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"head32\"></a>  Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuss the effectiveness of the Multi-Feature approach versus the Single feature variant. Namely, compare HoC+HoG with VGG.\n",
    "\n",
    "# Change the weights of each feature space and interpret the results. Which features better contribute to the overall effectiveness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
